{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_url=\"https://raw.githubusercontent.com/tomsercu/lstm/master/data\"\n",
    "filenames={split : f\"ptb.{split}.txt\" for split in [\"train\",\"valid\",\"test\"]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wrote ptb.train.txt to C:\\Users\\amrul\\programming\\deep_learning\\dl_projects\\nlp_with_dl_from_scratch\\datasets\\ptb.train.txt\n"
     ]
    }
   ],
   "source": [
    "import pathlib\n",
    "\n",
    "datasets_folder=pathlib.Path(r\"C:\\Users\\amrul\\programming\\deep_learning\\dl_projects\\nlp_with_dl_from_scratch\\datasets\")\n",
    "\n",
    "res = requests.get(f\"{base_url}/{filenames[\"train\"]}\")\n",
    "\n",
    "ptb_file=datasets_folder/filenames[\"train\"]\n",
    "ptb_file.write_text(res.text)\n",
    "print(f\"wrote {filenames[\"train\"]} to {ptb_file}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "text size : 5,101,618\n"
     ]
    }
   ],
   "source": [
    "text = ptb_file.read_text()\n",
    "print(f\"text size : {len(text):,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total of 937,128 words\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "from utils import tokenize\n",
    "\n",
    "words = tokenize(text,special_words=[\"<unk>\"])\n",
    "print(f\"total of {len(words):,} words\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vocab size : 9,654\n"
     ]
    }
   ],
   "source": [
    "vocab = list(set(words))\n",
    "print(f\"vocab size : {len(vocab):,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the        : 50,869\n",
      "<unk>      : 45,020\n",
      "N          : 32,481\n",
      "of         : 24,406\n",
      "to         : 23,662\n",
      "a          : 21,639\n",
      "in         : 18,010\n",
      "and        : 17,498\n",
      ".          : 16,709\n",
      "'          : 14,755\n",
      "s          : 11,934\n",
      "for        : 8,936\n",
      "that       : 8,931\n",
      "$          : 7,727\n",
      "is         : 7,337\n",
      "it         : 6,112\n",
      "said       : 6,027\n",
      "-          : 5,953\n",
      "on         : 5,653\n",
      "at         : 4,950\n",
      "by         : 4,915\n",
      "as         : 4,833\n",
      "from       : 4,724\n",
      "million    : 4,627\n",
      "with       : 4,585\n",
      "mr         : 4,326\n",
      "was        : 4,073\n",
      "be         : 3,936\n",
      "are        : 3,914\n",
      "its        : 3,846\n",
      "he         : 3,632\n",
      "n          : 3,598\n",
      "t          : 3,556\n",
      "but        : 3,541\n",
      "has        : 3,494\n",
      "an         : 3,477\n",
      "will       : 3,270\n",
      "have       : 3,245\n",
      "year       : 2,957\n",
      "new        : 2,809\n",
      "or         : 2,704\n",
      "company    : 2,686\n",
      "they       : 2,562\n",
      "this       : 2,438\n",
      "which      : 2,362\n",
      "would      : 2,321\n",
      "about      : 2,220\n",
      "market     : 2,101\n",
      "says       : 2,092\n",
      "more       : 2,065\n",
      "were       : 2,009\n",
      "u          : 1,942\n",
      "one        : 1,915\n",
      "billion    : 1,887\n",
      "his        : 1,852\n",
      "had        : 1,850\n",
      "their      : 1,838\n",
      "up         : 1,812\n",
      "stock      : 1,798\n",
      "than       : 1,737\n",
      "who        : 1,695\n",
      "some       : 1,668\n",
      "been       : 1,667\n",
      "also       : 1,617\n",
      "share      : 1,612\n",
      "other      : 1,566\n",
      "corp       : 1,474\n",
      "not        : 1,451\n",
      "we         : 1,397\n",
      "inc        : 1,372\n",
      "&          : 1,340\n",
      "i          : 1,287\n",
      "two        : 1,285\n",
      "if         : 1,281\n",
      "when       : 1,279\n",
      "last       : 1,262\n",
      "president  : 1,246\n",
      "shares     : 1,246\n",
      "out        : 1,245\n",
      "years      : 1,241\n",
      "all        : 1,227\n",
      "first      : 1,214\n",
      "trading    : 1,196\n",
      "after      : 1,175\n",
      "because    : 1,159\n",
      "quarter    : 1,158\n",
      "co         : 1,142\n",
      "could      : 1,136\n",
      "sales      : 1,126\n",
      "there      : 1,068\n",
      "business   : 1,051\n",
      "over       : 1,037\n",
      "only       : 1,028\n",
      "do         : 1,011\n",
      "such       : 1,010\n",
      "york       : 996\n",
      "can        : 996\n",
      "most       : 981\n",
      "into       : 961\n",
      "may        : 954\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "wcounter = Counter(words)\n",
    "n = 100\n",
    "for word,wfreq in wcounter.most_common(n):\n",
    "    print(f\"{word:<10} : {wfreq:,}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9656"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(wcounter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def build_co_matrix(corpus,word_to_id,window_size):\n",
    "    vocab_size = len(word_to_id)\n",
    "    cooccur_mat = np.zeros((vocab_size,vocab_size))\n",
    "    for word_pos,word_id in enumerate(corpus):\n",
    "        for context_idx in range(1, window_size+1):\n",
    "            left_word_pos = word_pos - context_idx\n",
    "            right_word_pos = word_pos + context_idx\n",
    "\n",
    "            if left_word_pos > 0:\n",
    "                left_word_id = corpus[left_word_pos]\n",
    "                cooccur_mat[word_id, left_word_id] += 1\n",
    "            \n",
    "            if right_word_pos < len(corpus):\n",
    "                right_word_id = corpus[right_word_pos]\n",
    "                cooccur_mat[word_id, right_word_id] += 1\n",
    "    return cooccur_mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_to_id = {word : idx for idx,(word,wfreq) in enumerate(wcounter.most_common(len(wcounter)))}\n",
    "id_to_word = {id:word for word,id in word_to_id.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = [word_to_id[word] for word in words]\n",
    "co_matrix = build_co_matrix(corpus,word_to_id,window_size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9656, 9656)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "co_matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3., 3., 0., ..., 0., 0., 0.])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "co_matrix[word_to_id[\"king\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I won't do this again\n",
    "# U,S,VT = np.linalg.svd(co_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "U matrix:\n",
      " [[-1.00000000e+00 -2.50185378e-16]\n",
      " [ 1.38777878e-16 -5.54700196e-01]\n",
      " [ 2.08166817e-16 -8.32050294e-01]]\n",
      "V^T matrix:\n",
      " [[-1.00000000e+00  2.22044605e-16  6.93889390e-17]\n",
      " [-6.93889390e-17 -2.22044605e-16 -1.00000000e+00]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy.sparse import csc_matrix\n",
    "from scipy.sparse.linalg import svds\n",
    "\n",
    "# Example sparse matrix\n",
    "# Using csc_matrix (Compressed Sparse Column matrix) for demonstration\n",
    "rows, cols = np.array([0, 1, 2]), np.array([0, 2, 2])\n",
    "data = np.array([1, 2, 3])\n",
    "sparse_matrix = csc_matrix((data, (rows, cols)), shape=(3, 3))\n",
    "sparse_matrix = sparse_matrix.astype(np.float64)\n",
    "\n",
    "# Perform SVD\n",
    "# k is the number of singular values and vectors to compute\n",
    "# You can adjust k based on your needs, but it must be less than the size of the matrix\n",
    "k = 2\n",
    "u, s, vt = svds(sparse_matrix, k=k)\n",
    "\n",
    "# u is the matrix of left singular vectors\n",
    "# vt is the matrix of right singular vectors, already transposed\n",
    "print(\"U matrix:\\n\", u)\n",
    "print(\"V^T matrix:\\n\", vt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "k=100\n",
    "u,s,vt = svds(co_matrix, k=k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9.868049310015605e-05"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "u[word_to_id[\"king\"]].dot(u[word_to_id[\"man\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7.965784284662087"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.log2(10000*5/(10*20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "co-occurrence matrix row sum of word king(its id 2235) : 86.0\n",
      "co-occurrence matrix column sum of word king(its id 2235) : 86.0\n"
     ]
    }
   ],
   "source": [
    "picked_up_word=\"king\"\n",
    "picked_up_word_id=word_to_id[picked_up_word]\n",
    "\n",
    "print(f\"co-occurrence matrix row sum of word {picked_up_word}(its id {picked_up_word_id}) : {co_matrix[picked_up_word_id].sum()}\")\n",
    "print(f\"co-occurrence matrix column sum of word {picked_up_word}(its id {picked_up_word_id}) : {co_matrix[:,picked_up_word_id].sum()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total count : 2,054,333.0\n",
      "corpus size : 1,027,168\n"
     ]
    }
   ],
   "source": [
    "print(f\"total count : {co_matrix.sum():,}\")\n",
    "print(f\"corpus size : {len(corpus):,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\amrul\\AppData\\Local\\Temp\\ipykernel_12704\\2251961259.py:1: RuntimeWarning: divide by zero encountered in log2\n",
      "  np.log2(0)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "-inf"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.log2(0)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dl_312_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
